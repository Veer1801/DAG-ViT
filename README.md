# DAG-ViT: Mathematical Formulation

This repository contains the **mathematical formulation** of **DAG-ViT (Directed Acyclic Graph Vision Transformer)** â€” a novel architecture that combines adaptive token selection with DAG-based relational reasoning to improve image understanding tasks.

---

## ğŸ§  About the Paper

**Title**: *Mathematical Formulation of DAG-ViT: A Vision Transformer with Adaptive Graph Reasoning*  
**Author**: [Veer Patel](mailto:veerpatel1801@gmail.com)  
**Format**: IEEE Conference Style  
**Paper Type**: Theoretical & Mathematical Modeling

---

## ğŸ“„ Paper Overview

> Traditional Vision Transformers (ViTs) rely on uniform token grids and lack relational context between patches. DAG-ViT introduces:
>
> - ğŸ” **Adaptive Tokenization** via soft attention
> - ğŸ” **Directed Acyclic Graphs (DAG)** to model inter-token dependencies
> - ğŸ§  **Hybrid Reasoning** using GNNs and Transformers
> - âš–ï¸ **Differentiable DAG Loss** to ensure acyclic structure

The approach is especially useful in **medical imaging**, **satellite analysis**, and other tasks where spatial relationships and interpretability matter.

---

## ğŸ“˜ Contents

| File | Description |
|------|-------------|
| `DAG-ViT_Math_Formulation.pdf` | ğŸ“„ Final compiled paper in IEEE format (mathematical formulation only) |

---

## ğŸ”¬ Applications

- ğŸ©» Fracture Detection in Medical X-rays  
- ğŸŒ Deforestation and Urban Monitoring from Satellite Images  
- ğŸ§¬ Lesion Localization and Anatomical Reasoning  
- ğŸ” Low-token, high-efficiency inference tasks

---

## ğŸ“Œ Citation

Coming soon... (Once published or shared on arXiv)

---

## ğŸ“¬ Contact

For questions, collaborations, or feedback:

- ğŸ“§ veerpatel1801@gmail.com

---

## â­ï¸ Star the repo if you find this paper helpful!

